{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from multiprocessing import Process\n",
    "\n",
    "# Step 1: get protein data from fasta file\n",
    "def gen_seqs(filename):\n",
    "    seq = ''\n",
    "    with open(filename) as f:\n",
    "        for line_no, l in enumerate(f):\n",
    "            if line_no == 0:\n",
    "                pass\n",
    "            elif l[0] == '>':\n",
    "                yield seq\n",
    "                seq = ''\n",
    "            else:\n",
    "                seq = seq + l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to test this\n",
    "def seqs_from(seq, word_len):\n",
    "    word_sets = []\n",
    "    for start_pos in range(0,word_len):\n",
    "        word_set = []\n",
    "        for word_start_pos in range(start_pos, len(seq) - word_len + 1, word_len):\n",
    "            word_set.append(seq[word_start_pos:(word_start_pos+word_len)])\n",
    "        word_sets.append(word_set)\n",
    "    return word_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2: set up dictionaries and transform data\n",
    "def make_dictionaries(seq_generator, input_filename, word_len):\n",
    "    word_count = dict()\n",
    "    dictionary = dict()\n",
    "    rev_dictionary = dict()\n",
    "    index = 0\n",
    "    for in_seq in seq_generator(input_filename):\n",
    "        sub_seqs = seqs_from(in_seq, word_len)\n",
    "        for seq in sub_seqs:\n",
    "            for word in seq: # word is just an amino acid for now\n",
    "                if word not in rev_dictionary.keys():\n",
    "                    dictionary[index] = word\n",
    "                    rev_dictionary[word] = index\n",
    "                    word_count[word] = 1\n",
    "                    index = index + 1\n",
    "                else:\n",
    "                    word_count[word] = word_count[word] + 1\n",
    "        \n",
    "    return dictionary, rev_dictionary, word_count\n",
    "\n",
    "def gen_transformed_data(rev_dictionary, seq_generator, input_filename, word_len):\n",
    "    for in_seq in seq_generator(input_filename):\n",
    "        sub_seqs = seqs_from(in_seq, word_len)\n",
    "        for seq in sub_seqs:\n",
    "            transformed_data = []\n",
    "            for word in seq: # word is just an amino acid for now\n",
    "                transformed_data.append(rev_dictionary[word])\n",
    "            yield transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: make data generator and save everything to disk\n",
    "\n",
    "def gen_seq_batch(seq, skip_window):\n",
    "    min_index = 0\n",
    "    max_index = len(seq) -1 \n",
    "    batch = []\n",
    "    labels = []\n",
    "    for b_ind in range(max_index):\n",
    "        for l_ind in range(b_ind-skip_window, b_ind+skip_window+1):\n",
    "            if (l_ind < min_index) or (l_ind > max_index):\n",
    "                pass\n",
    "            elif b_ind == l_ind:\n",
    "                pass\n",
    "            else:\n",
    "                batch.append(seq[b_ind])\n",
    "                labels.append(seq[l_ind])\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_pre_process(input_filename='../data/protein/test.fasta',\n",
    "                    dictionaries_filename='../data/protein/dictionaries',\n",
    "                    batches_filename='../data/protein/batches',\n",
    "                    skip_window=2,\n",
    "                    down_sample_rate=100,\n",
    "                    word_len=1):\n",
    "\n",
    "    # save dictionaries\n",
    "    dictionary, rev_dictionary, word_count = make_dictionaries(gen_seqs, input_filename, word_len)\n",
    "    \n",
    "    count_s = json.dumps(word_count)\n",
    "    dict_s = json.dumps(dictionary)\n",
    "    rev_dict_s = json.dumps(rev_dictionary)\n",
    "\n",
    "    with open(dictionaries_filename + '_' + str(word_len) + '.json', 'w') as f_out:\n",
    "        f_out.write(dict_s + '\\n' + rev_dict_s + '\\n' + count_s + '\\n')\n",
    "\n",
    "    # save data batches\n",
    "    transformed_seqs = gen_transformed_data(rev_dictionary, gen_seqs, input_filename, word_len)\n",
    "    with open(batches_filename + '_' + str(word_len) + '.csv', 'w') as f_out:\n",
    "        for transformed_seq in transformed_seqs:\n",
    "            ind = 0\n",
    "            batch, labels = gen_seq_batch(transformed_seq, skip_window)\n",
    "            for i in range(len(batch)):\n",
    "                if (ind % down_sample_rate) == 0:\n",
    "                    f_out.write(str(batch[i]) + ',' + str(labels[i]) + '\\n')\n",
    "                ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1-mers\n",
    "p1 = Process(target=run_pre_process,\n",
    "             kwargs=dict(input_filename='../data/protein/bacteria_nonredundant_protein.fasta',\n",
    "                   skip_window=3,\n",
    "                   down_sample_rate=100,\n",
    "                   word_len=1))\n",
    "p1.start()\n",
    "\n",
    "# 2-mers\n",
    "p2 = Process(target=run_pre_process,\n",
    "             kwargs=dict(input_filename='../data/protein/bacteria_nonredundant_protein.fasta',\n",
    "                   skip_window=1,\n",
    "                   down_sample_rate=100,\n",
    "                   word_len=2))\n",
    "p2.start()\n",
    "\n",
    "# 3-mers\n",
    "p3 = Process(target=run_pre_process,\n",
    "             kwargs=dict(input_filename='../data/protein/bacteria_nonredundant_protein.fasta',\n",
    "                   skip_window=1,\n",
    "                   down_sample_rate=100,\n",
    "                   word_len=3))\n",
    "p3.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
